{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Times of India Article Display Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata...\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os, zipfile, pathlib, shutil\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import IFrame\n",
    "import zipp\n",
    "\n",
    "# Definitions\n",
    "\n",
    "def empty(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def sanitize(request_list):\n",
    "    wanted_articles = []\n",
    "    unrecognized_articles = []\n",
    "    \n",
    "    all_articles = set(metadata.index)\n",
    "\n",
    "    for article in request_list:\n",
    "        clean_art = str(article).strip()\n",
    "        if clean_art in all_articles:\n",
    "            wanted_articles.append(clean_art)\n",
    "        elif clean_art == '':\n",
    "            pass\n",
    "        else: \n",
    "            unrecognized_articles.append(clean_art)\n",
    "    \n",
    "    if len(unrecognized_articles) > 0:\n",
    "        print(\"The following entries were not recognized as articles:\")\n",
    "        [print(repr(x)) for x in unrecognized_articles]\n",
    "    if len(wanted_articles) == 0:\n",
    "        raise ValueError('No valid article IDs Recognized!')\n",
    "    return(wanted_articles)\n",
    "\n",
    "def request_input():\n",
    "    request = input(\"What article IDs shall I look up for you?\")\n",
    "    request_list = re.split(\",|;| \", request)\n",
    "    clear_output()\n",
    "    return request_list\n",
    "\n",
    "def unpack_pdfs(request_list, metadata):\n",
    "    print(\"Unpacking requested pdfs...\")\n",
    "\n",
    "    df = metadata.loc[request_list]\n",
    "    zips_to_open = df.pdf_zip.unique().tolist()\n",
    "\n",
    "    for zip_file in zips_to_open:\n",
    "\n",
    "        files_to_extract = df[df['pdf_zip'] == zip_file].pdf_file.unique().tolist()   \n",
    "\n",
    "        with zipfile.ZipFile(os.path.join('PDF', zip_file)) as zf: \n",
    "\n",
    "            for file in files_to_extract:\n",
    "                zf.extract(file, path=\"temp\")\n",
    "    print(\"Done!\")\n",
    "\n",
    "def display_article(metadata, article):\n",
    "    \n",
    "    pdf_file = metadata.at[article, 'pdf_file']\n",
    "    pdf_file = os.path.join(\"temp\", pdf_file)\n",
    "    \n",
    "    display(IFrame(src=pdf_file, width='100%', height='700px'))\n",
    "    \n",
    "    pub_date = metadata.at[article, 'pub_date']\n",
    "    objecttypes = metadata.at[article, 'objecttypes']\n",
    "    objecttypes = objecttypes.split(';')\n",
    "    \n",
    "    txt_zip = metadata.at[article, 'txt_zip']\n",
    "    txt_file = metadata.at[article, 'txt_file']\n",
    "    \n",
    "    txt_zip = os.path.join('TXT', txt_zip)\n",
    "    \n",
    "    with zipfile.ZipFile(txt_zip) as zf:\n",
    "        with zf.open(txt_file) as f:\n",
    "            text = f.read()\n",
    "    \n",
    "    print(f'Article ID: {article} \\t Published: {pub_date}')\n",
    "    print('Object Types:\\t', ', '.join(objecttypes))\n",
    "    \n",
    "    \n",
    "#     print('Article text:', '\\n\\n', text, '\\n')\n",
    "    \n",
    "    linked_function(article)\n",
    "    \n",
    "    clear_output()\n",
    "    \n",
    "# Next step is to introduce the choice to save and end or save and continue.\n",
    "\n",
    "def save_results():\n",
    "    try:\n",
    "        save_function()\n",
    "        save_indicator = 1\n",
    "    except:\n",
    "        save_indicator = 0\n",
    "    \n",
    "    if save_indicator == 1:\n",
    "        print('changes saved!')\n",
    "    else:\n",
    "        print('no save function detected; changes not saved.')\n",
    "    \n",
    "\n",
    "\n",
    "def display_article_chunk(request_list, chunk_number, metadata, continue_indicator, chunk_size):\n",
    "    \n",
    "    number_of_chunks = len(request_list)//chunk_size + (len(request_list) % chunk_size > 0)\n",
    "    \n",
    "    if int(continue_indicator) == 1:\n",
    "        n = 0\n",
    "        save_indicator = 0\n",
    "        \n",
    "        \n",
    "        if len(request_list) >= chunk_size*chunk_number+1:\n",
    "            this_chunk = request_list[chunk_size*chunk_number:chunk_size*(chunk_number+1)]\n",
    "        else:\n",
    "            this_chunk = request_list[chunk_size*chunk_number:]\n",
    "\n",
    "        for article in this_chunk:\n",
    "            n+=1\n",
    "            print(f\"Here's article {n} of {len(this_chunk)}, in set {chunk_number+1} of {number_of_chunks}:\")\n",
    "            display_article(metadata, article)\n",
    "    elif int(continue_indicator) == 0:\n",
    "        return continue_indicator\n",
    "    \n",
    "    save_results()\n",
    "    \n",
    "    if chunk_number != number_of_chunks:\n",
    "        continue_indicator = input('enter 1 to continue, or 0 to exit.')\n",
    "        while int(continue_indicator) not in set([1, 0]):\n",
    "            continue_indicator = input('enter 1 to continue, or 0 to exit.')\n",
    "    elif chunk_number == number_of_chunks:\n",
    "        continue_indicator = 0\n",
    "    return continue_indicator\n",
    "    \n",
    "def display_requested_articles(metadata, chunk_size=15):\n",
    "    try:\n",
    "        request_list = get_display_list()\n",
    "        if type(request_list) != list:\n",
    "            raise TypeError('Please make sure get_display_function() is returning a list of article IDs.')\n",
    "    except NameError:\n",
    "        request_list = request_input()\n",
    "    \n",
    "    request_list = sanitize(request_list)\n",
    "    \n",
    "    unpack_pdfs(request_list, metadata)\n",
    "    \n",
    "    number_of_chunks = len(request_list)//chunk_size + (len(request_list) % chunk_size > 0)\n",
    "    \n",
    "    continue_indicator = 1\n",
    "    \n",
    "    while int(continue_indicator) == 1:\n",
    "        for chunk_number in range(number_of_chunks):\n",
    "            continue_indicator = display_article_chunk(request_list, chunk_number, metadata, continue_indicator, chunk_size)\n",
    "\n",
    "    empty(\"temp\")\n",
    "    \n",
    "\n",
    "# Import Data Index\n",
    "\n",
    "def load_metadata():\n",
    "    print('Loading metadata...')\n",
    "    with zipfile.ZipFile(os.path.join('TOI_metadata.zip')) as zf:\n",
    "        with zf.open('TOI_metadata.csv') as file:\n",
    "            metadata = pd.read_csv(file, usecols=['record_id', \n",
    "                                                  'pub_date', \n",
    "                                                  'txt_zip', \n",
    "                                                  'txt_file',\n",
    "                                                  'pdf_zip',\n",
    "                                                  'pdf_file',\n",
    "                                                  'objecttypes'], dtype='object').set_index('record_id')\n",
    "\n",
    "    print('done \\n')\n",
    "    return metadata\n",
    "\n",
    "metadata = load_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Articles to display\n",
    "\n",
    "If you have a list or custom script to output a list of articles, you can add it in the cell below, defining it as 'get_display_list'. If no list-defining function is provided, the next cell will prompt for manual input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add list-defining function here:\n",
    "\n",
    "def get_display_list():\n",
    "  \n",
    "    # read in the training data\n",
    "    td = pd.read_csv('../pogrep/training_data.csv', dtype='object', index_col='record_id')\n",
    "\n",
    "    # read in the second_opinion work so far\n",
    "    second_opinion_df = pd.read_csv('../pogrep/temp/second_opinion.csv', dtype='object', index_col=0)\n",
    "    second_opinion = second_opinion_df.second_opinion.to_dict()\n",
    "\n",
    "    request_list = list(set(td.index.tolist()) - set(second_opinion_df.index.tolist()))\n",
    "    \n",
    "    return request_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input and Save functions (Optional)\n",
    "If you would like to have a custom input function run after display (say, a coding assignment), and if you would like to save the results of the input function, add them in the cell below. Define them as linked_function() and save_function() respectively. If linked_function remains undefined, the page will default to a \"Press enter to continue\" dialog box with no save function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_opinion_df = pd.read_csv('../pogrep/temp/second_opinion.csv', dtype='object', index_col=0)\n",
    "second_opinion = second_opinion_df.second_opinion.to_dict()\n",
    "\n",
    "def linked_function(article):\n",
    "    new_judgment = ''\n",
    "    while type(new_judgment) != bool:\n",
    "        new_judgment = input(\"Is this a pogrom narrative? (y or 1 = Yes, n or 0 = No)\")\n",
    "        if new_judgment == 'y' or '1':\n",
    "            new_judgment = True\n",
    "        elif new_judgment == 'n' or '0':\n",
    "            new_judgment = False\n",
    "        else:\n",
    "            print(\"I'm not sure how to interpret that.\")\n",
    "\n",
    "    second_opinion.update({int(article):str(new_judgment)})\n",
    "    \n",
    "def save_function():\n",
    "    opinion = {'second_opinion': second_opinion}\n",
    "    pd.DataFrame(opinion).to_csv('../pogrep/temp/second_opinion.csv')\n",
    "    # Note: to load the newly completed segment, you'll need to drop '\\_new' from the new file, and replace the old one. For safety, this should be done manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changes saved!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter 1 to continue, or 0 to exit. 0\n"
     ]
    }
   ],
   "source": [
    "display_requested_articles(metadata, chunk_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
